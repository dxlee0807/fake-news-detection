{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "clean_news_df = pd.read_csv(os.path.join(os.getcwd(),\"dataset\\\\clean_news_df.csv\"))\n",
    "\n",
    "# remove empty values\n",
    "clean_news_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_or_fake</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>budget fight loom republican flip fiscal scrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>military accept transgender recruit monday pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>senior republican senator let mueller job wash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>fbi russia probe help australian diplomat tip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>trump want postal service charge much amazon s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>fake</td>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>mcpain john mccain furious iran treat sailor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>fake</td>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>justice yahoo settle mail privacy class action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>fake</td>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>sunnistan ally safe zone plan take territorial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>fake</td>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>blow million jazeera america finally call quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>fake</td>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>navy sailor hold iranian military sign neocon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44889 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      true_or_fake                                               text  \\\n",
       "0             true  As U.S. budget fight looms, Republicans flip t...   \n",
       "1             true  U.S. military to accept transgender recruits o...   \n",
       "2             true  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3             true  FBI Russia probe helped by Australian diplomat...   \n",
       "4             true  Trump wants Postal Service to charge 'much mor...   \n",
       "...            ...                                                ...   \n",
       "44893         fake  McPain: John McCain Furious That Iran Treated ...   \n",
       "44894         fake  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "44895         fake  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "44896         fake  How to Blow $700 Million: Al Jazeera America F...   \n",
       "44897         fake  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      budget fight loom republican flip fiscal scrip...  \n",
       "1      military accept transgender recruit monday pen...  \n",
       "2      senior republican senator let mueller job wash...  \n",
       "3      fbi russia probe help australian diplomat tip ...  \n",
       "4      trump want postal service charge much amazon s...  \n",
       "...                                                  ...  \n",
       "44893  mcpain john mccain furious iran treat sailor w...  \n",
       "44894  justice yahoo settle mail privacy class action...  \n",
       "44895  sunnistan ally safe zone plan take territorial...  \n",
       "44896  blow million jazeera america finally call quit...  \n",
       "44897  navy sailor hold iranian military sign neocon ...  \n",
       "\n",
       "[44889 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training set and validation set\n",
    "\n",
    "# train = 80, test = 20\n",
    "# random_seed = 42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = clean_news_df['cleaned_text'].str.split()\n",
    "y = clean_news_df['true_or_fake']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True,random_state=42,test_size=0.2,stratify=y)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Word2Vec model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(X_train, vector_size=200, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87044\n"
     ]
    }
   ],
   "source": [
    "vocab=list(w2v_model.wv.key_to_index.keys())\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dxlee\\AppData\\Local\\Temp\\ipykernel_10952\\2131801328.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_train])\n",
      "C:\\Users\\dxlee\\AppData\\Local\\Temp\\ipykernel_10952\\2131801328.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_test])\n"
     ]
    }
   ],
   "source": [
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_test])\n",
    "X_train_avg = []\n",
    "for v in X_train_vect:\n",
    "        X_train_avg.append(v.mean(axis=0))\n",
    "\n",
    "X_test_avg = []\n",
    "for v in X_test_vect:\n",
    "        X_test_avg.append(v.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# loading the baseline model\n",
    "gbc_base = GradientBoostingClassifier(random_state=42)\n",
    "gbc_base.fit(X_train_avg, y_train)\n",
    "\n",
    "# gbc_base.score(X_test_avg,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.958119848518601\n",
      "Precision:  0.9527230590961762\n",
      "Recall:  0.9598412327807612\n",
      "F1-Score:  0.9562688997441265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.96      0.96      4695\n",
      "        true       0.95      0.96      0.96      4283\n",
      "\n",
      "    accuracy                           0.96      8978\n",
      "   macro avg       0.96      0.96      0.96      8978\n",
      "weighted avg       0.96      0.96      0.96      8978\n",
      "\n",
      "Confusion Matrix [TP FP FN TN]: \n",
      " [4491  204  172 4111]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score, classification_report\n",
    "\n",
    "gbc_base_preds = gbc_base.predict(X_test_avg)\n",
    "print(\"Accuracy: \",accuracy_score(y_true=y_test,y_pred=gbc_base_preds))\n",
    "print(\"Precision: \",precision_score(y_true=y_test,y_pred=gbc_base_preds,pos_label='true'))\n",
    "print(\"Recall: \",recall_score(y_true=y_test,y_pred=gbc_base_preds,pos_label='true'))\n",
    "print(\"F1-Score: \",f1_score(y_true=y_test,y_pred=gbc_base_preds,pos_label='true'))\n",
    "print(classification_report(y_test, gbc_base_preds))\n",
    "\n",
    "print(\"Confusion Matrix [TP FP FN TN]: \\n\",confusion_matrix(y_true=y_test,y_pred=gbc_base_preds).ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "# #creating Scoring parameter: \n",
    "# scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#            'precision': make_scorer(precision_score,pos_label='true'),'recall':make_scorer(recall_score,pos_label='true')}\n",
    "\n",
    "# # A parameter distribution\n",
    "\n",
    "# parameters = {\n",
    "#     \"loss\":[\"deviance\"],\n",
    "#     \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "#     \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"max_depth\":[3,5,8],\n",
    "#     \"max_features\":[\"log2\",\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\",  \"squared_error\"],\n",
    "#     \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "#     \"n_estimators\":[10]\n",
    "#     }\n",
    "# #passing the scoring function in the GridSearchCV\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=5)\n",
    "\n",
    "# clf.fit(X_train_avg, y_train)\n",
    "# #converting the clf.cv_results to dataframe\n",
    "# df=pd.DataFrame.from_dict(clf.cv_results_)\n",
    "# #here Possible inputs for cross validation is cv=2, there two split split0 and split1\n",
    "# df[['split0_test_accuracy','split1_test_accuracy','split0_test_precision','split1_test_precision','split0_test_recall','split1_test_recall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomised Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   n_iter=500,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.2],\n",
       "                                        'loss': ['deviance'],\n",
       "                                        'max_depth': [2, 5, 8],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': array([0.1, 0.3, 0.5]),\n",
       "                                        'min_samples_split': array([0.1, 0.3, 0.5]),\n",
       "                                        'min_weight_fraction_leaf': [0.0, 0.25,\n",
       "                                                                     0.5],\n",
       "                                        'n_estimators': [10, 20],\n",
       "                                        'subsample': [0.5, 0.75, 1.0]},\n",
       "                   random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 3),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 3),\n",
    "    \"min_weight_fraction_leaf\":[0.0, 0.25, 0.5],\n",
    "    \"max_depth\":[2,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"squared_error\"],\n",
    "    \"subsample\":[0.5, 0.75, 1.0],\n",
    "    \"n_estimators\":[10,20]\n",
    "    }\n",
    "\n",
    "gbc_random_cv = RandomizedSearchCV(estimator=GradientBoostingClassifier(random_state=42),param_distributions=parameters,n_iter=500,cv=4,scoring='accuracy',random_state=42)\n",
    "gbc_random_cv.fit(X_train_avg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1.0,\n",
       " 'n_estimators': 20,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'min_samples_split': 0.1,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 5,\n",
       " 'loss': 'deviance',\n",
       " 'learning_rate': 0.2,\n",
       " 'criterion': 'squared_error'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9336155045667186\n",
      "Precision:  0.9246717346233587\n",
      "Recall:  0.9371935559187485\n",
      "F1-Score:  0.9308905380333953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.93      0.94      4695\n",
      "        true       0.92      0.94      0.93      4283\n",
      "\n",
      "    accuracy                           0.93      8978\n",
      "   macro avg       0.93      0.93      0.93      8978\n",
      "weighted avg       0.93      0.93      0.93      8978\n",
      "\n",
      "Confusion Matrix [TP FP FN TN]: \n",
      " [4368  327  269 4014]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score, classification_report\n",
    "\n",
    "gbc_random_cv_preds = gbc_random_cv.predict(X_test_avg)\n",
    "print(\"Accuracy: \",accuracy_score(y_true=y_test,y_pred=gbc_random_cv_preds))\n",
    "print(\"Precision: \",precision_score(y_true=y_test,y_pred=gbc_random_cv_preds,pos_label='true'))\n",
    "print(\"Recall: \",recall_score(y_true=y_test,y_pred=gbc_random_cv_preds,pos_label='true'))\n",
    "print(\"F1-Score: \",f1_score(y_true=y_test,y_pred=gbc_random_cv_preds,pos_label='true'))\n",
    "print(classification_report(y_test, gbc_random_cv_preds))\n",
    "\n",
    "print(\"Confusion Matrix [TP FP FN TN]: \\n\",confusion_matrix(y_true=y_test,y_pred=gbc_random_cv_preds).ravel())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
