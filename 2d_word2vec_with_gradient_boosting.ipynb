{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "clean_news_df = pd.read_csv(os.path.join(os.getcwd(),\"dataset\\\\clean_news_df.csv\"))\n",
    "\n",
    "# remove empty values\n",
    "clean_news_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_or_fake</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>budget fight loom republican flip fiscal scrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>military accept transgender recruit monday pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>senior republican senator let mueller job wash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>fbi russia probe help australian diplomat tip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>trump want postal service charge much amazon s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>fake</td>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>mcpain john mccain furious iran treat sailor w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>fake</td>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>justice yahoo settle mail privacy class action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>fake</td>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>sunnistan ally safe zone plan take territorial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>fake</td>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>blow million jazeera america finally call quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>fake</td>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>navy sailor hold iranian military sign neocon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44889 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      true_or_fake                                               text  \\\n",
       "0             true  As U.S. budget fight looms, Republicans flip t...   \n",
       "1             true  U.S. military to accept transgender recruits o...   \n",
       "2             true  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3             true  FBI Russia probe helped by Australian diplomat...   \n",
       "4             true  Trump wants Postal Service to charge 'much mor...   \n",
       "...            ...                                                ...   \n",
       "44893         fake  McPain: John McCain Furious That Iran Treated ...   \n",
       "44894         fake  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "44895         fake  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "44896         fake  How to Blow $700 Million: Al Jazeera America F...   \n",
       "44897         fake  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      budget fight loom republican flip fiscal scrip...  \n",
       "1      military accept transgender recruit monday pen...  \n",
       "2      senior republican senator let mueller job wash...  \n",
       "3      fbi russia probe help australian diplomat tip ...  \n",
       "4      trump want postal service charge much amazon s...  \n",
       "...                                                  ...  \n",
       "44893  mcpain john mccain furious iran treat sailor w...  \n",
       "44894  justice yahoo settle mail privacy class action...  \n",
       "44895  sunnistan ally safe zone plan take territorial...  \n",
       "44896  blow million jazeera america finally call quit...  \n",
       "44897  navy sailor hold iranian military sign neocon ...  \n",
       "\n",
       "[44889 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training set and validation set\n",
    "\n",
    "# train = 80, test = 20\n",
    "# random_state = 42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = clean_news_df['cleaned_text'].str.split()\n",
    "y = clean_news_df['true_or_fake']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True,random_state=42,test_size=0.2,stratify=y)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Word2Vec model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(X_train, vector_size=200, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87044\n"
     ]
    }
   ],
   "source": [
    "vocab=list(w2v_model.wv.key_to_index.keys())\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dxlee\\AppData\\Local\\Temp\\ipykernel_17436\\2131801328.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_train])\n",
      "C:\\Users\\dxlee\\AppData\\Local\\Temp\\ipykernel_17436\\2131801328.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_test])\n"
     ]
    }
   ],
   "source": [
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_test])\n",
    "X_train_avg = []\n",
    "for v in X_train_vect:\n",
    "        X_train_avg.append(v.mean(axis=0))\n",
    "\n",
    "X_test_avg = []\n",
    "for v in X_test_vect:\n",
    "        X_test_avg.append(v.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Baseline Model Evaluation ======\n",
      "Confusion Matrix [TP FP FN TN]: \n",
      " [4490  205  173 4110]\n",
      "Accuracy : 0.958\n",
      "Precision: 0.952\n",
      "Recall   : 0.960\n",
      "F1-Score : 0.956\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.96      0.96      4695\n",
      "        true       0.95      0.96      0.96      4283\n",
      "\n",
      "    accuracy                           0.96      8978\n",
      "   macro avg       0.96      0.96      0.96      8978\n",
      "weighted avg       0.96      0.96      0.96      8978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "\n",
    "# fitting the baseline model\n",
    "gbc_base = GradientBoostingClassifier(random_state=42)\n",
    "gbc_base.fit(X_train_avg, y_train)\n",
    "\n",
    "# evaluate the baseline model\n",
    "gbc_base_preds = gbc_base.predict(X_test_avg)\n",
    "print(\"====== Baseline Model Evaluation ======\")\n",
    "print(\"Confusion Matrix [TP FP FN TN]: \\n\",confusion_matrix(y_true=y_test,y_pred=gbc_base_preds).ravel())\n",
    "print(f\"Accuracy : {accuracy_score(y_true=y_test,y_pred=gbc_base_preds):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_true=y_test,y_pred=gbc_base_preds,pos_label='true'):.3f}\",)\n",
    "print(f\"Recall   : {recall_score(y_true=y_test,y_pred=gbc_base_preds,pos_label='true'):.3f}\")\n",
    "print(f\"F1-Score : {f1_score(y_true=y_test,y_pred=gbc_base_preds,pos_label='true'):.3f}\")\n",
    "print(\"\\nClassification Report\\n\",classification_report(y_true=y_test,y_pred=gbc_base_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   n_iter=2000,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.2],\n",
       "                                        'loss': ['deviance'],\n",
       "                                        'max_depth': [2, 5, 8],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': array([0.1       , 0.23333333, 0.36666667, 0.5       ]),\n",
       "                                        'min_samples_split': array([0.1       , 0.23333333, 0.36666667, 0.5       ]),\n",
       "                                        'min_weight_fraction_leaf': [0.0, 0.25,\n",
       "                                                                     0.5],\n",
       "                                        'n_estimators': [10, 20],\n",
       "                                        'subsample': [0.5, 0.75, 1.0]},\n",
       "                   random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 4),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 4),\n",
    "    \"min_weight_fraction_leaf\":[0.0, 0.25, 0.5],\n",
    "    \"max_depth\":[2,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"squared_error\"],\n",
    "    \"subsample\":[0.5, 0.75, 1.0],\n",
    "    \"n_estimators\":[10,20]\n",
    "    }\n",
    "\n",
    "gbc_random_cv = RandomizedSearchCV(estimator=GradientBoostingClassifier(random_state=42),param_distributions=parameters,n_iter=2000,cv=5,scoring='accuracy',random_state=42)\n",
    "gbc_random_cv.fit(X_train_avg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1.0,\n",
       " 'n_estimators': 20,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'min_samples_split': 0.1,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 5,\n",
       " 'loss': 'deviance',\n",
       " 'learning_rate': 0.2,\n",
       " 'criterion': 'squared_error'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Hyperparameter Tuned Model Evaluation ======\n",
      "Confusion Matrix [TP FP FN TN]: \n",
      " [4351  344  282 4001]\n",
      "Accuracy : 0.930\n",
      "Precision: 0.921\n",
      "Recall   : 0.934\n",
      "F1-Score : 0.927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "# evaluate the tuned model\n",
    "gbc_random_cv_preds = gbc_random_cv.predict(X_test_avg)\n",
    "print(\"====== Hyperparameter Tuned Model Evaluation ======\")\n",
    "print(\"Confusion Matrix [TP FP FN TN]: \\n\",confusion_matrix(y_true=y_test,y_pred=gbc_random_cv_preds).ravel())\n",
    "print(f\"Accuracy : {accuracy_score(y_true=y_test,y_pred=gbc_random_cv_preds):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_true=y_test,y_pred=gbc_random_cv_preds,pos_label='true'):.3f}\",)\n",
    "print(f\"Recall   : {recall_score(y_true=y_test,y_pred=gbc_random_cv_preds,pos_label='true'):.3f}\")\n",
    "print(f\"F1-Score : {f1_score(y_true=y_test,y_pred=gbc_random_cv_preds,pos_label='true'):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
